{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_ADDRESS = 'mid-term-project.ca2jkepgjpne.us-east-2.rds.amazonaws.com' \n",
    "POSTGRES_PORT = '5432' \n",
    "POSTGRES_USERNAME = 'lhl_student' \n",
    "POSTGRES_PASSWORD = 'lhl_student' \n",
    "POSTGRES_DBNAME='mid_term_project'\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, \n",
    "                                                                                        password=POSTGRES_PASSWORD, \n",
    "                                                                                        ipaddress=POSTGRES_ADDRESS, \n",
    "                                                                                        port=POSTGRES_PORT, \n",
    "                                                                                        dbname=POSTGRES_DBNAME)) \n",
    "\n",
    "cnx = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flight=pd.read_sql_query('''SELECT * FROM flights ORDER BY RANDOM() LIMIT 10000;''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>1436</td>\n",
       "      <td>UA</td>\n",
       "      <td>N37290</td>\n",
       "      <td>1436</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>23.172619</td>\n",
       "      <td>4.725108</td>\n",
       "      <td>16.795996</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>25.610931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>HA</td>\n",
       "      <td>HA</td>\n",
       "      <td>HA</td>\n",
       "      <td>181</td>\n",
       "      <td>HA</td>\n",
       "      <td>N485HA</td>\n",
       "      <td>181</td>\n",
       "      <td>12402</td>\n",
       "      <td>ITO</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>23.172619</td>\n",
       "      <td>4.725108</td>\n",
       "      <td>16.795996</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>25.610931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>AA</td>\n",
       "      <td>3477</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N542EA</td>\n",
       "      <td>3477</td>\n",
       "      <td>11066</td>\n",
       "      <td>CMH</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>B6</td>\n",
       "      <td>730</td>\n",
       "      <td>B6</td>\n",
       "      <td>N527JB</td>\n",
       "      <td>730</td>\n",
       "      <td>10732</td>\n",
       "      <td>BQN</td>\n",
       "      <td>...</td>\n",
       "      <td>173.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>23.172619</td>\n",
       "      <td>4.725108</td>\n",
       "      <td>16.795996</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>25.610931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>815</td>\n",
       "      <td>AS</td>\n",
       "      <td>N585AS</td>\n",
       "      <td>815</td>\n",
       "      <td>14747</td>\n",
       "      <td>SEA</td>\n",
       "      <td>...</td>\n",
       "      <td>398.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>23.172619</td>\n",
       "      <td>4.725108</td>\n",
       "      <td>16.795996</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>25.610931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0  2019-11-28                 UA                 UA          UA   \n",
       "1  2018-01-03                 HA                 HA          HA   \n",
       "2  2018-02-15                 AA       AA_CODESHARE          AA   \n",
       "3  2018-07-27                 B6                 B6          B6   \n",
       "4  2018-03-27                 AS                 AS          AS   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                1436                UA   N37290               1436   \n",
       "1                 181                HA   N485HA                181   \n",
       "2                3477                MQ   N542EA               3477   \n",
       "3                 730                B6   N527JB                730   \n",
       "4                 815                AS   N585AS                815   \n",
       "\n",
       "   origin_airport_id origin  ... crs_elapsed_time  actual_elapsed_time  \\\n",
       "0              13930    ORD  ...            220.0                230.0   \n",
       "1              12402    ITO  ...             55.0                 50.0   \n",
       "2              11066    CMH  ...             96.0                 92.0   \n",
       "3              10732    BQN  ...            173.0                172.0   \n",
       "4              14747    SEA  ...            398.0                359.0   \n",
       "\n",
       "  air_time flights  distance  carrier_delay  weather_delay  nas_delay  \\\n",
       "0    197.0     1.0    1250.0      23.172619       4.725108  16.795996   \n",
       "1     36.0     1.0     216.0      23.172619       4.725108  16.795996   \n",
       "2     64.0     1.0     296.0      69.000000       0.000000   0.000000   \n",
       "3    151.0     1.0    1129.0      23.172619       4.725108  16.795996   \n",
       "4    343.0     1.0    2701.0      23.172619       4.725108  16.795996   \n",
       "\n",
       "   security_delay  late_aircraft_delay  \n",
       "0        0.048701            25.610931  \n",
       "1        0.048701            25.610931  \n",
       "2        0.000000             0.000000  \n",
       "3        0.048701            25.610931  \n",
       "4        0.048701            25.610931  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date                0\n",
       "mkt_unique_carrier     0\n",
       "branded_code_share     0\n",
       "mkt_carrier            0\n",
       "mkt_carrier_fl_num     0\n",
       "op_unique_carrier      0\n",
       "tail_num               0\n",
       "op_carrier_fl_num      0\n",
       "origin_airport_id      0\n",
       "origin                 0\n",
       "origin_city_name       0\n",
       "dest_airport_id        0\n",
       "dest                   0\n",
       "dest_city_name         0\n",
       "crs_dep_time           0\n",
       "dep_time               0\n",
       "dep_delay              0\n",
       "taxi_out               0\n",
       "wheels_off             0\n",
       "wheels_on              0\n",
       "taxi_in                0\n",
       "crs_arr_time           0\n",
       "arr_time               0\n",
       "arr_delay              0\n",
       "cancelled              0\n",
       "diverted               0\n",
       "dup                    0\n",
       "crs_elapsed_time       0\n",
       "actual_elapsed_time    0\n",
       "air_time               0\n",
       "flights                0\n",
       "distance               0\n",
       "carrier_delay          0\n",
       "weather_delay          0\n",
       "nas_delay              0\n",
       "security_delay         0\n",
       "late_aircraft_delay    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fl_date                0\n",
       "mkt_unique_carrier     0\n",
       "branded_code_share     0\n",
       "mkt_carrier            0\n",
       "mkt_carrier_fl_num     0\n",
       "op_unique_carrier      0\n",
       "tail_num               0\n",
       "op_carrier_fl_num      0\n",
       "origin_airport_id      0\n",
       "origin                 0\n",
       "origin_city_name       0\n",
       "dest_airport_id        0\n",
       "dest                   0\n",
       "dest_city_name         0\n",
       "crs_dep_time           0\n",
       "dep_time               0\n",
       "dep_delay              0\n",
       "taxi_out               0\n",
       "wheels_off             0\n",
       "wheels_on              0\n",
       "taxi_in                0\n",
       "crs_arr_time           0\n",
       "arr_time               0\n",
       "arr_delay              0\n",
       "cancelled              0\n",
       "diverted               0\n",
       "dup                    0\n",
       "crs_elapsed_time       0\n",
       "actual_elapsed_time    0\n",
       "air_time               0\n",
       "flights                0\n",
       "distance               0\n",
       "carrier_delay          0\n",
       "weather_delay          0\n",
       "nas_delay              0\n",
       "security_delay         0\n",
       "late_aircraft_delay    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the missing values with their mean\n",
    "carr_delay_mean=df_flight['carrier_delay'].astype('float').mean(axis=0)\n",
    "wea_delay_mean=df_flight['weather_delay'].astype('float').mean(axis=0)\n",
    "nas_delay_mean=df_flight['nas_delay'].astype('float').mean(axis=0)\n",
    "sec_delay_mean=df_flight['security_delay'].astype('float').mean(axis=0)\n",
    "aircraft_delay_mean=df_flight['late_aircraft_delay'].astype('float').mean(axis=0)\n",
    "\n",
    "\n",
    "df_flight['carrier_delay'].replace(np.nan, carr_delay_mean, inplace=True)\n",
    "df_flight['weather_delay'].replace(np.nan, wea_delay_mean, inplace=True)\n",
    "df_flight['nas_delay'].replace(np.nan, nas_delay_mean, inplace=True)\n",
    "df_flight['security_delay'].replace(np.nan, sec_delay_mean, inplace=True)\n",
    "df_flight['late_aircraft_delay'].replace(np.nan, aircraft_delay_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time', 'dep_time',\n",
       "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in',\n",
       "       'crs_arr_time', 'arr_time', 'arr_delay', 'cancelled', 'diverted', 'dup',\n",
       "       'crs_elapsed_time', 'actual_elapsed_time', 'air_time', 'flights',\n",
       "       'distance', 'carrier_delay', 'weather_delay', 'nas_delay',\n",
       "       'security_delay', 'late_aircraft_delay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time', 'dep_time',\n",
       "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in',\n",
       "       'crs_arr_time', 'arr_time', 'arr_delay', 'cancelled',\n",
       "       'cancellation_code', 'diverted', 'dup', 'crs_elapsed_time',\n",
       "       'actual_elapsed_time', 'air_time', 'flights', 'distance',\n",
       "       'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay',\n",
       "       'late_aircraft_delay', 'first_dep_time', 'total_add_gtime',\n",
       "       'longest_add_gtime', 'no_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('flights_rand-Copy1.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_flights = df.drop(['dep_time', 'actual_elapsed_time', 'air_time','dep_delay', 'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', 'arr_time', 'dest', 'dest_city_name','origin', 'origin_city_name', 'branded_code_share', 'carrier_delay','weather_delay','nas_delay','security_delay', 'late_aircraft_delay', 'first_dep_time', 'total_add_gtime','longest_add_gtime','cancelled', 'cancellation_code', 'diverted', 'dup', 'flights', 'no_name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'mkt_carrier', 'mkt_carrier_fl_num',\n",
       "       'op_unique_carrier', 'tail_num', 'op_carrier_fl_num',\n",
       "       'origin_airport_id', 'dest_airport_id', 'crs_dep_time', 'crs_arr_time',\n",
       "       'arr_delay', 'crs_elapsed_time', 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_time_mode = df_flights['dep_time'].mode()\n",
    "arr_time_mode = df_flights['arr_time'].mode()\n",
    "\n",
    "tail_number_mode = df_flights['tail_num'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_flights['arr_time'] = df_flights['arr_time'].fillna(int(arr_time_mode))\n",
    "df_flights['dep_time'] = df_flights['dep_time'].fillna(int(dep_time_mode))\n",
    "\n",
    "df_flights['tail_num'] = df_flights['tail_num'].fillna(str(tail_number_mode[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['dep_delay'] = df_flights['dep_delay'].fillna(df_flights['dep_delay'].mean())\n",
    "df_flights['taxi_in'] = df_flights['taxi_in'].fillna(df_flights['taxi_in'].mean())\n",
    "df_flights['arr_delay'] = df_flights['arr_delay'].fillna(df_flights['arr_delay'].mean())\n",
    "df_flights['actual_elapsed_time'] = df_flights['actual_elapsed_time'].fillna(df_flights['actual_elapsed_time'].mean())\n",
    "df_flights['air_time'] = df_flights['air_time'].fillna(df_flights['air_time'].mean())\n",
    "df_flights['taxi_out'] = df_flights['taxi_out'].fillna(df_flights['taxi_out'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>DL</td>\n",
       "      <td>5799</td>\n",
       "      <td>CP</td>\n",
       "      <td>N615CZ</td>\n",
       "      <td>5799</td>\n",
       "      <td>14869</td>\n",
       "      <td>12280</td>\n",
       "      <td>1100</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1204</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>UA</td>\n",
       "      <td>6129</td>\n",
       "      <td>YV</td>\n",
       "      <td>N88325</td>\n",
       "      <td>6129</td>\n",
       "      <td>12266</td>\n",
       "      <td>11540</td>\n",
       "      <td>955</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1051</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>809</td>\n",
       "      <td>WN</td>\n",
       "      <td>N7841A</td>\n",
       "      <td>809</td>\n",
       "      <td>13232</td>\n",
       "      <td>11433</td>\n",
       "      <td>1640</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1850</td>\n",
       "      <td>1831.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>AA</td>\n",
       "      <td>1830</td>\n",
       "      <td>AA</td>\n",
       "      <td>N556UW</td>\n",
       "      <td>1830</td>\n",
       "      <td>12889</td>\n",
       "      <td>11057</td>\n",
       "      <td>750</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1508</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-19</td>\n",
       "      <td>AS</td>\n",
       "      <td>3300</td>\n",
       "      <td>OO</td>\n",
       "      <td>N176SY</td>\n",
       "      <td>3300</td>\n",
       "      <td>14831</td>\n",
       "      <td>10423</td>\n",
       "      <td>938</td>\n",
       "      <td>932.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1514</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1476.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_carrier  mkt_carrier_fl_num op_unique_carrier tail_num  \\\n",
       "0  2018-07-27          DL                5799                CP   N615CZ   \n",
       "1  2018-10-08          UA                6129                YV   N88325   \n",
       "2  2018-10-31          WN                 809                WN   N7841A   \n",
       "3  2019-10-15          AA                1830                AA   N556UW   \n",
       "4  2018-06-19          AS                3300                OO   N176SY   \n",
       "\n",
       "   op_carrier_fl_num  origin_airport_id  dest_airport_id  crs_dep_time  \\\n",
       "0               5799              14869            12280          1100   \n",
       "1               6129              12266            11540           955   \n",
       "2                809              13232            11433          1640   \n",
       "3               1830              12889            11057           750   \n",
       "4               3300              14831            10423           938   \n",
       "\n",
       "   dep_time  dep_delay  taxi_out  taxi_in  crs_arr_time  arr_time  arr_delay  \\\n",
       "0    1056.0       -4.0      18.0      5.0          1204    1202.0       -2.0   \n",
       "1    1016.0       21.0      22.0      2.0          1051    1111.0       20.0   \n",
       "2    1638.0       -2.0      11.0      6.0          1850    1831.0      -19.0   \n",
       "3     750.0        0.0      20.0     15.0          1508    1506.0       -2.0   \n",
       "4     932.0       -6.0      14.0      5.0          1514    1458.0      -16.0   \n",
       "\n",
       "   crs_elapsed_time  actual_elapsed_time  air_time  distance  \n",
       "0              64.0                 66.0      43.0     188.0  \n",
       "1             116.0                115.0      91.0     667.0  \n",
       "2              70.0                 53.0      36.0     228.0  \n",
       "3             258.0                256.0     221.0    1916.0  \n",
       "4             216.0                206.0     187.0    1476.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights=df_flights.dropna()\n",
    "df_flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['fl_date'] = pd.to_datetime(df_flights['fl_date'], errors='coerce')\n",
    "df_flights['month'] = df_flights['fl_date'].dt.month\n",
    "df_flights['day_of_week'] = df_flights['fl_date'].dt.dayofweek\n",
    "df_flights['day_of_month'] = df_flights['fl_date'].dt.day\n",
    "df_flights['year'] = df_flights['fl_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights=df_flights.drop('fl_date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the types categories\n",
    "df_flights[\"mkt_carrier\"] = df_flights[\"mkt_carrier\"].astype(\"category\")\n",
    "df_flights[\"op_unique_carrier\"] = df_flights[\"op_unique_carrier\"].astype(\"category\")\n",
    "df_flights[\"tail_num\"] = df_flights[\"tail_num\"].astype(\"category\")\n",
    "df_flights[\"op_carrier_fl_num\"] = df_flights[\"op_carrier_fl_num\"].astype(\"category\")\n",
    "df_flights[\"origin_airport_id\"] = df_flights[\"origin_airport_id\"].astype(\"category\")\n",
    "df_flights[\"dest_airport_id\"] = df_flights[\"dest_airport_id\"].astype(\"category\")\n",
    "df_flights[\"mkt_carrier_fl_num\"] = df_flights[\"mkt_carrier_fl_num\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE AIRPORTS AND TAILNUM\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "df_flights['mkt_carrier'] = encoder.fit_transform(df_flights[['mkt_carrier']])\n",
    "df_flights['mkt_carrier_fl_num'] = encoder.fit_transform(df_flights[['mkt_carrier_fl_num']])\n",
    "df_flights['op_unique_carrier'] = encoder.fit_transform(df_flights[['op_unique_carrier']])\n",
    "df_flights['tail_num'] = encoder.fit_transform(df_flights[['tail_num']])\n",
    "df_flights['op_carrier_fl_num'] = encoder.fit_transform(df_flights[['op_carrier_fl_num']])\n",
    "df_flights['origin_airport_id'] = encoder.fit_transform(df_flights[['origin_airport_id']])\n",
    "df_flights['dest_airport_id'] = encoder.fit_transform(df_flights[['dest_airport_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8666\n",
       "2    1295\n",
       "3      38\n",
       "Name: flight_duration_type, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to air_time and arr_delay to category\n",
    "def flight_duration(x):\n",
    "    if x <=180:\n",
    "        return '1'\n",
    "    elif x >180 and x<360:\n",
    "        return '2'\n",
    "    elif x>360:\n",
    "        return '3'\n",
    "\n",
    "df_flights['flight_duration_type']=df_flights['air_time'].apply(lambda x: flight_duration(x))\n",
    "\n",
    "df_flights['flight_duration_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply different selection techniques to find out which one will be the best for our problems.\n",
    "\n",
    "- Original Features vs. PCA conponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mkt_carrier', 'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id',\n",
       "       'crs_dep_time', 'dep_time', 'dep_delay', 'taxi_out', 'wheels_off',\n",
       "       'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'arr_delay',\n",
       "       'crs_elapsed_time', 'actual_elapsed_time', 'air_time', 'distance',\n",
       "       'month', 'day_of_week', 'day_of_month', 'year', 'flight_duration_type',\n",
       "       'arr_delay_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Short'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-63a53c3981af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcomponents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[1;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Short'"
     ]
    }
   ],
   "source": [
    "features=df_flights[['mkt_carrier_fl_num','origin_airport_id', 'dest_airport_id','crs_dep_time', 'dep_time', 'dep_delay', 'taxi_out', 'taxi_in', 'crs_arr_time', 'arr_time', 'arr_delay',\n",
    "       'crs_elapsed_time', 'actual_elapsed_time', 'air_time', 'distance',\n",
    "       'month', 'day_of_week', 'day_of_month', 'year', 'flight_duration_type']]\n",
    "\n",
    "pca=PCA(n_components=3)\n",
    "components=pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'components' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-e7b4eca9e57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_flights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'components' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig=px.scatter(components, x=0, y=1, color=df_flights['month'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mkt_carrier            float64\n",
       "mkt_carrier_fl_num     float64\n",
       "op_unique_carrier      float64\n",
       "tail_num               float64\n",
       "op_carrier_fl_num      float64\n",
       "origin_airport_id      float64\n",
       "dest_airport_id        float64\n",
       "crs_dep_time             int64\n",
       "dep_time               float64\n",
       "dep_delay              float64\n",
       "taxi_out               float64\n",
       "taxi_in                float64\n",
       "crs_arr_time             int64\n",
       "arr_time               float64\n",
       "arr_delay              float64\n",
       "crs_elapsed_time       float64\n",
       "actual_elapsed_time    float64\n",
       "air_time               float64\n",
       "distance               float64\n",
       "month                    int64\n",
       "day_of_week              int64\n",
       "day_of_month             int64\n",
       "year                     int64\n",
       "arr_delay_cat            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use different ML techniques to predict each problem.\n",
    "\n",
    "- linear / logistic / multinomial logistic regression\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "- SVM\n",
    "- XGBoost\n",
    "- The ensemble of your own choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into train and test\n",
    "\n",
    "X=np.array(df_flights.drop('dep_delay', axis=1))\n",
    "y=np.array(df_flights['dep_delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4., 21., -2., ...,  9., 44., -7.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = (y - y.mean()) / y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lab_enc=LabelEncoder()\n",
    "y_train=lab_enc.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-c2e771effdd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Logistics Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_log=LogisticRegression()\n",
    "model_log.fit(X_train, y_train)\n",
    "y_pred_log=model_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2421.3721103160897"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2440.1064770476414"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_linear=LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "y_pred_linear=model_linear.predict(X_test)\n",
    "r2_score(y_test, y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have data from 2018 and 2019 to develop models. Use different evaluation metrics for each problem and compare the performance of different models.\n",
    "\n",
    "You are required to predict delays on **out of sample** data from **first 7 days (1st-7th) of January 2020** and to share the file with LighthouseLabs. Sample submission can be found in the file **_sample_submission.csv_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "## Stretch Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables are **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY**. We need to do additional transformations because these variables are not binary but continuos. For each flight that was delayed, we need to have one of these variables as 1 and others 0.\n",
    "\n",
    "It can happen that we have two types of delays with more than 0 minutes. In this case, take the bigger one as 1 and others as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **CANCELLED**. The main problem here is going to be huge class imbalance. We have only very little cancelled flights with comparison to all flights. It is important to do the right sampling before training and to choose correct evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
